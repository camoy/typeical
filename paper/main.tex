% $Id: template.tex 11 2007-04-03 22:25:53Z jpeltier $

\documentclass{vgtc}                          % final (conference style)
%\documentclass[review]{vgtc}                 % review
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint]{vgtc}               % preprint
%\documentclass[electronic]{vgtc}             % electronic version

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Figures should be in CMYK or Grey scale format, otherwise, colour
%% shifting may occur during the printing process.

%% These few lines make a distinction between latex and pdflatex calls and they
%% bring in essential packages for graphics and font handling.
%% Note that due to the \DeclareGraphicsExtensions{} call it is no longer necessary
%% to provide the the path and extension of a graphics file:
%% \includegraphics{diamondrule} is completely sufficient.
%%
\ifpdf%                                % if we use pdflatex
  \pdfoutput=1\relax                   % create PDFs from pdfLaTeX
  \pdfcompresslevel=9                  % PDF Compression
  \pdfoptionpdfminorversion=7          % create PDF 1.7
  \ExecuteOptions{pdftex}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg} % for pdflatex we expect .pdf, .png, or .jpg files
\else%                                 % else we use pure latex
  \ExecuteOptions{dvips}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.eps}     % for pure latex we expect eps files
\fi%

\usepackage[T1]{fontenc}% to use more chars & support copy & paste of special chars from PDF

%% it is recomended to use ``\autoref{sec:bla}'' instead of ``Fig.~\ref{sec:bla}''
\graphicspath{{figures/}{pictures/}{images/}{./}} % where to search for the images

\usepackage{microtype}                 % use micro-typography (slightly more compact, better to read)
\PassOptionsToPackage{warn}{textcomp}  % to address font issues with \textrightarrow
\usepackage{textcomp}                  % use better special symbols
\usepackage{mathptmx}                  % use matching math font
\usepackage{times}                     % we use Times as the main font
\renewcommand*\ttdefault{txtt}         % a nicer typewriter font
\usepackage{cite}                      % needed to automatically sort the references
\usepackage{tabu}                      % only used for the table example
\usepackage{booktabs}                  % only used for the table example
%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

\usepackage{xspace}

\usepackage{hyperref}
\usepackage[noabbrev]{cleveref}
\usepackage{caption}
\captionsetup[table]{skip=10pt}
\usepackage{tabularx}
\usepackage{todonotes} %TODO: Remove after all TODO's are gone

%% ORCID
\usepackage{scalerel}
\usepackage{tikz}
\usetikzlibrary{svg.path}

\definecolor{orcidlogocol}{HTML}{A6CE39}
\tikzset{
  orcidlogo/.pic={
    \fill[orcidlogocol] svg{M256,128c0,70.7-57.3,128-128,128C57.3,256,0,198.7,0,128C0,57.3,57.3,0,128,0C198.7,0,256,57.3,256,128z};
    \fill[white] svg{M86.3,186.2H70.9V79.1h15.4v48.4V186.2z}
                 svg{M108.9,79.1h41.6c39.6,0,57,28.3,57,53.6c0,27.5-21.5,53.6-56.8,53.6h-41.8V79.1z M124.3,172.4h24.5c34.9,0,42.9-26.5,42.9-39.7c0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z}
                 svg{M88.7,56.8c0,5.5-4.5,10.1-10.1,10.1c-5.6,0-10.1-4.6-10.1-10.1c0-5.6,4.5-10.1,10.1-10.1C84.2,46.7,88.7,51.3,88.7,56.8z};
  }
}

\newcommand\orcid[2]{\href{https://orcid.org/#2}{#1 \mbox{\scalerel*{
\begin{tikzpicture}[yscale=-1,transform shape]
\pic{orcidlogo};
\end{tikzpicture}
}{|}}}}

%% ===================================== Commands
\newcommand{\code}[1]{\texttt{\small{#1}}}
\newcommand{\ourmethodplaintext}{\textsc{TyVis}\xspace}
\newcommand{\ourmethod}{{\sc \ourmethodplaintext}\xspace}
\newcommand{\pkgNumAnalyzed}{412\xspace}
\newcommand{\settingsTab}{{\sc Settings}\xspace}

\newcommand{\osfsupplementplain}{osf.io/mc6zt}
\newcommand{\osfsupplement}{\formattedurl{https://\osfsupplementplain}{\osfsupplementplain}}
\newcommand{\osfsupplementlong}{\formattedurl{https://\osfsupplementplain}{https://\osfsupplementplain}}

\newcommand{\osfprereg}{\formattedurl{https://\osfpreregplain}{\osfpreregplain}}

\newcommand{\formattedurl}[2]{\href{#1}{\small\texttt{#2}}\xspace}

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{0}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in an IEEE VGTC sponsored conference.}

\title{\ourmethodplaintext: Visualizing Function Type Signatures in R}

\newcommand{\mailtohref}[1]{\href{mailto:camoy@ccs.neu.edu;belyakovay@ccs.neu.edu;alexi@ccs.neu.edu;dibartolomeo.s@northeastern.edu;c.dunne@northeastern.edu}{\color{black}#1}}

\author{
    \orcid{Cameron Moy}{0000-0002-4384-6351}%
    \thanks{%
        E-mails: \mailtohref{%
        [~%
        {camoy} |
        {belyakovay} |
        {alexi}~]@ccs.neu.edu,
        [~%
        {dibartolomeo.s} |
        {c.dunne}~]@northeastern.edu}
        \vspace{0.55in}
    }\\%
    \and \orcid{Julia Belyakova}{0000-0002-7490-8500}\\%
    \and \orcid{Alexi Turcotte}{0000-0002-0381-0477}\\%
    \and \orcid{Sara Di Bartolomeo}{0000-0001-9517-3526}\\%
    \and \orcid{Cody Dunne}{0000-0002-1609-9776}\\%
}
\affiliation{\scriptsize Northeastern University}

\teaser{
  \includegraphics[width=\textwidth]{img/teaser.png}
  \caption{Type signatures for a subset of R's base package functions shown in the type flow visualization of \ourmethod.
  The function name is listed at the top followed by the first two argument types.
  All argument and return types are shown in the full visualization.}
}

\abstract{
  Data-driven approaches to programming language design are uncommon.
  Despite the availability of large code repositories, distilling semantically-rich information from programs remains difficult.
  Important dimensions, like run-time type data, are inscrutable without the appropriate tools.
  We contribute \ourmethod, an interactive visualization for exploring and analyzing type information from program execution traces --- aiding user understanding of function type signatures across many executions.
  The system uses flows to intuitively represent categorical and numerical aspects of type signatures.
  Insights derived from our visualization are aimed at informing language design decisions --- specifically of a new gradual type system currently being developed for the R programming language.
  A full version of this paper with all supplemental material is available at \osfsupplementlong
}

%% ACM Computing Classification System (CCS).
%% See <http://www.acm.org/about/class> for details.
%% We recommend the 2012 system <http://www.acm.org/about/class/class/2012>
%% For the 2012 system use the ``\CCScatTwelve'' which command takes four arguments.
%% The 1998 system <http://www.acm.org/about/class/class/2012> is still possible
%% For the 1998 system use the ``\CCScat'' which command takes four arguments.
%% In both cases the last two arguments (1998) or last three (2012) can be empty.

\CCScatlist{
  \CCScatTwelve{Human-centered computing}{Visualization}{Visualization systems and tools}{}
}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\firstsection{Introduction}

\maketitle

\bgroup
\def\arraystretch{1.75}
\begin{table*}
  \centering
  \begin{tabularx}{\linewidth}{c|c|c|X}
    \textbf{Domain Goals} & \textbf{Search Task} & \textbf{Query Task} & \multicolumn{1}{c}{\textbf{Abstract Task Description}} \\
    \hline
    Find function      & Locate & Identify & 
    Finding a function is a locate task, where the target function is known, but its location within the package hierarchy is not.
    Once the desired function is found, a user must be able to identify relevant data of interest. \\

    Determine types    & Browse & Identify & 
    Determining types is a browse task, where the target type signature is unknown, but the location of the function of interest is known.
    While browsing, a user must be able to identify the frequencies of particular type signatures.\\

    Compare signatures & Lookup & Compare  & 
    Comparing type signatures is a lookup task where both target type signatures have already been located.
    A user must be able to discern how often a signature is used compared to another, both within a function and across different functions.\\
  \end{tabularx}
  \caption{
  Domain goals for programming language designers trying to understand function type signatures at run time.
  We captured these goals from interviews and created mid-level and low-level task abstractions based on Brehmer \& Munzner's multi-level task typology~\cite{brehmer:2013}.}
  \label{tab:tasks}
\end{table*}
\egroup

Programming languages commonly evolve by decree.
Often, the language designer decides that a new feature is necessary, or that a past feature was ill-conceived.
Thus, the language moves forward --- forcing its users to adapt to the changes.
Sometimes, these changes are the result of rigorous theory or the product of community feedback.
However, rarely is language design informed by empirical data on how programs are \emph{actually written} in practice~\cite{hanenberg:2010}.
Why so?

Thanks to the prevalence of open source code, collecting data on the usage of a popular programming language is feasible.
Vast quantities of code are publicly available online on language-specific package servers like npm for JavaScript or CRAN for R.
Some repositories, like CRAN, only include high-quality libraries.
Using a curated source of code mitigates some data collection concerns like code duplication~\cite{lopes:2017}.

To inform programming language design, the collected data needs to be analyzed and interpreted.
Programs are complex and highly structured, so simple semantically-unaware metrics like ``lines of code'' carry little significance.
Therefore, researchers often employ static and dynamic analyses to gather information about specific aspects of programs.
Even then, it may be difficult to make sense of the results of these analyses, especially if the data set is large.

Following the design study ``lite'' methodology~\cite{syeda:2020}, we built \ourmethod, an interactive visualization of run-time type signatures.
A type signature is a description of the argument and return types that a particular function is called with at run-time.
\ourmethod was created with the R programming language in mind, and builds on a data set of execution traces mined from the unit tests and vignettes of the most widely used libraries in the R ecosystem.

The tool supports three broad tasks:
\begin{itemize}
  \setlength\itemsep{0em}
  \item filtering the data set down to an amenable subset;
  \item understanding the types of function arguments and returns;
  \item comparing type signatures across different functions.
\end{itemize}

For exploring and filtering the data set, \ourmethod relies on treemaps to represent R packages and functions, with node size conveying relative popularity.
Additionally, one can search directly for a function by name.
Once a subset of one or more functions is selected, their type signatures are encoded as flows over types, where flow width is proportional to frequency.
These flows can be readily compared within the same function, or between different functions.

\ourmethod can assist language designers during multiple phases of development.
For example, exploratory data analysis can identify unexpected edge cases, or weed out language designs that are incompatible with existing programs.
\ourmethod was built in support of a new gradual type system for R, whose adoption depends on integrating well with existing code.
A type system provides a conservative approximation of run-time types --- thus, insight into existing type usage can inform decision-making.
Without a data-driven tool, gradual type system designers are left to guess about how their language is used in practice.
Our aim is to eliminate such guesswork.
While our visualization was created for a specific use case, it is not limited to R and can be used to analyze type usage in any language where similar data are available.
Even beyond this domain, linking parallel sets and treemaps can be a powerful visualization technique.
For example, parallel sets can display survey responses with many categorical questions~\cite{kosara:2006}, but a large number of responses can introduce too much visual clutter.
Hierarchical filtering, with a treemap, can eliminate irrelevant information and recover an interpretable representation.

%%

\section{Background and Prior Work}

R is a lazy, multi-paradigm, dynamically-typed programming language widely used for statistical computing~\cite{morandat:2012}.
Unlike statically-typed languages, R code contains no type annotations and never passes through a typechecker.
At run-time, functions may be called with values of arbitrary type, and may return values of arbitrary type.\footnote{
  We use the word ``type'' to mean what others may call a ``type tag.''
  This is a run-time concept --- we do not assume a static type system   because there is none.
  Indeed, the goal is to help design one!
  A ``type signature'' in this context is one particular configuration of argument and return types a function is called with at run-time.
}

Being a dynamically-typed language with widespread use in a single domain, R is a good target for a gradual type system.
A gradual type system permits the integration of static and dynamic typing~\cite{siek:2006,tobin-hochstadt:2006}, and is capable of seamlessly mixing typed and untyped regions of code.

For statically-typed languages, the type system is usually an inseparable part of the language.
Since they are designed at the same time, the type system precedes any code written in the language.
Gradual type systems, by contrast, are often designed atop an existing dynamically-typed language~\cite{tobin-hochstadt:2016}.
Many R programs already exist, so a successful gradual type system must work well with extant code.
Thus, gradual type system designers must first understand existing language idioms, and then work to accommodate them.
Our tool assists during the understanding phase of development.

We are not aware of any previous work that applies visualization techniques for the purpose of programming language design.
However, there are existing publications on understanding software through visualization.
Bohnet et al.~\cite{bohnet:2009} visualize massive program execution traces to improve developer comprehension of large software systems.
Their tool applies pruning and summarization techniques to reduce trace size.
They focus on call topology, describing the structure of function invocations, rather than types.
Telea et al.~\cite{telea:2009} also develop a methodology for displaying call structure.
However, they visualize call graphs of systems in their entirety, rather than individual execution traces.
\ourmethod has elements of both, investigating the system as a whole, but doing so via execution traces.
In addition to standard call graphs, LaToza and Myers~\cite{latoza:2011} adorn nodes and edges with extra information, allowing the user to gain further understanding of the system under examination.
This includes grouping methods that come from the same class --- a basic form of type data.

%%

\section{Data and Collection} \label{sec:data}

We used the data set from Turcotte et al.~\cite{turcotte:2020} that consists of traces from over $760,000$ lines of R code and $534,000$ lines of native code.
This code was obtained from CRAN, a curated repository of R packages that is widely used in the community.
The data set consists of all packages with at least $65\%$ code coverage and at least $5$ reverse dependencies (clients using that package).
Out of the over $15,000$ packages distributed on CRAN, this amounted to \pkgNumAnalyzed packages.

Execution traces were recorded by running a dynamic analysis over the test, example, and vignette code of each package.
A vignette is a form of documentation that weaves together prose and executable code.
An execution trace is a list of function type signatures containing, among other attributes, the function name and type tags for each argument and return value.
For example, the expression {\tt 0 < 1} would be recorded as the type signature {\tt integer $\to$ integer $\to$ logical}, meaning that the function {\tt <} took two integer values and returned a logical value (i.e. a boolean).
The type tags are assigned by the dynamic analysis and refine the actual type tags at run-time.
For instance, the analysis assigns the scalar tag {\tt double} to a singleton vector of double values because R does not have native support for scalars.
The data set is a table of reduced execution traces.
Because \ourmethod was designed for the analysis of types, not all information in the traces is relevant.

While \ourmethod has only been instantiated with data from R execution traces, the architecture is not limited to R.
Any dynamically-typed language, or statically-typed language with run-time tag information, could be instrumented to generate data for the tool.
As long as the trace output adheres to the correct schema, \ourmethod will work properly without any modifications.

%%

\begin{figure*}
 \centering
 \includegraphics[width=\linewidth]{img/typevis.png}
 \caption{An overview of \ourmethod, with type flows on the left and the package hierarchy on the right. Here, the {\tt length.unit} and {\tt valid.unit} functions from the {\tt grid} package are both selected and displayed simultaneously.}
 \label{fig:typevis}
\end{figure*}

\section{Task Abstraction}

We interviewed the primary researcher developing a gradual type system for R (and third author of this work) to inventory relevant domain-specific tasks.
Additionally, we sought his and other researchers' feedback throughout the creation of \ourmethod to ensure it was adequately meeting requirements.
The domain-specific goals identified were:

\begin{enumerate}
\item {\bf Find Function.}
  Quickly search for a particular function and identify basic information.
  This includes how often the function is called and which package contains it.
\item {\bf Determine Types.}
  Given a specific function, determine its argument and return types, and identify the frequency of specific type signatures.
  A user should be able to readily infer, for example, if a function is polymorphic (i.e. accepts arguments of multiple different types) or if it is a predicate (i.e. returns a logical value).
\item {\bf Compare Signatures.}
  Compare the occurrence of type signatures within a specific function, and across many different functions.
  A user must be able to isolate individual signatures and exmaine them in the context of others.
\end{enumerate}

These goals can be classified using an abstract task analysis framework.
See \cref{tab:tasks} for a categorization of these domain tasks with the mid-level and low-level abstract task taxonomy established by Brehmer and Munzner~\cite{brehmer:2013}.

%%

\section{Design and Implementation}

\ourmethod is an interactive web-based visualization that permits real-time data exploration, even with large data sets.
The default data set of R execution traces, described in \cref{sec:data}, contains over a million rows.

\Cref{fig:typevis} shows the heart of \ourmethod --- the type flow panel on the left and the function filtering panel on the right.
Type signatures shown on the left reflect the subset of the data selected on the right.
By default, if no subset is selected, the type flow panel shows several of the most frequent function type signatures in the entire data set.
Various aspects of the system, such as the number of type signatures shown at once, can be tweaked by the user if desired; for this, a separate \settingsTab tab is provided.

\subsection{Hierarchical Package Visualization}

The right-hand panel of \cref{fig:typevis} contains three elements: a search bar, a package treemap, and a function treemap.
All three components are linked.
Selecting a package in the top treemap causes the bottom treemap to show only functions defined in that package; additionally, the type flow panel gets updated with the most frequent function type signatures in the package.
Selecting a function in the bottom treemap makes the type flow panel show only signatures of that function.
Entering a function name in the search bar updates the type flow panel immediately.

These different components support at least two modes of search: quick function lookup and package exploration.
If a user has a specific function in mind, they can type its name into the search bar and see its type signatures straight away; the search bar supports autocomplete that is able to select one function among thousands.
If, on the other hand, one wants to browse all available packages and functions, the treemap view is more applicable.
The area of a block in the function treemap (package treemap) conveys the log-scaled frequency of calls to that function (to all functions defined in that package).
Log-scaling and pagination keep elements of the treemaps legible, even when absolute size differences are significant.

The data set can additionally be filtered by analyzed package, in other words, the package containing the call site of a function, not the definition site.
As mentioned in \cref{sec:data}, the data set contains information from \pkgNumAnalyzed analyzed packages, which are all taken into account by default.
However, a user can limit the set of analyzed packages, using a search bar in \settingsTab.

Although treemaps are often used for displaying hierarchical data~\cite{shneiderman:1992}, in \ourmethod they have a flat structure.
The packages in our data are not deeply structured, so the treemaps in \cref{fig:typevis} are only one level deep.
However, in many programming languages, like Java, package systems contain deeply nested namespace hierarchies.
The treemap idiom is appropriate for navigation of such hierarchies, and \ourmethod could be modified to handle that.

By default, \ourmethod allows only one function to be selected at a time, but it can be configured for multiple function selection.
In the example from \cref{fig:typevis}, the {\tt length.unit} and {\tt valid.unit} functions from the {\tt grid} package are both selected.
These functions are rendered simultaneously in the type flow panel, allowing the user to make comparisons between them.
However, if the user wants to explore different functions rather than compare them, the default one-function mode is more appropriate.

\subsection{Types as Flows}

Prominently featured in the center of \cref{fig:typevis} is a parallel sets diagram encoding the type signatures of the selected functions as flows.
Parallel sets, proposed by Kosara et al.~\cite{kosara:2006}, are ideally suited for type signatures.
Each data point can be thought of as a tuple $(f, \tau_1, \ldots, \tau_n, \tau_r)$ corresponding to the function name, argument types, and return type.
Every component of that tuple is categorical, and we are interested in visualizing the frequencies of these points.
This is the exact use-case for parallel sets.

Flows begin at a node labeling a function, curve across each argument type in order, and terminate at the return type.
Widths are proportional to how many times a function is called with that signature during analysis.
Flow segments are filled with a hue-varying color scale, determined by the type where the segment ends.
Beneath each node label is an approximate count of either: how many times the function was invoked if the node represents a function, or how often a value of that type was recorded during analysis if the node represents a type.

In \cref{fig:typevis}, the {\tt length.unit} function is called with two different type signatures at run-time.
Most frequently, the function is used with the signature {\tt double $\to$ integer}, but a substantial fraction of the time it is used as {\tt double[] $\to$ integer}.
Here, {\tt double[]} stands for an array of doubles with arbitrary dimension.

Interactivity significantly enhances the usability of the parallel sets diagram.
Hovering over a flow will highlight the entire path of the flow and will fade out all other functions, as shown in \cref{fig:typevis}.
When displaying many flows at the same time, highlighting becomes critical for user comprehension.
Additional quantitative information about the flow is supplied on-demand while hovering.
Clicking a flow will focus on that function only, filtering away all others; double clicking outside flows will bring back the previous view.
The number of flows shown at a time is limited, and will paginate if that threshold is exceeded.

Flow layout is a necessary consideration for a legible visualization~\cite{sugiyama:1981}.
\Cref{fig:decross} exemplifies what happens if flow layout is not adequately computed.
The top layout was generated without any flow decrossing algorithm, while the bottom layout applies optimal decrossing.
Even with highlighting, the top visualization is almost impossible to understand due to excessive flow overlap.
To maintain real-time performance, we use two different decrossing methods.
First, the system attempts to construct a layout with the globally optimal solution, minimizing the amount of flow crossing by solving a mixed-integer linear program~\cite{ebner:2005}.
Unfortunately, for even moderately sized graphs this can take too long to compute.
Therefore, after about $1$ second, the optimal algorithm is terminated if it has not finished, and the final layout is computed by a faster algorithm that only minimizes local crossing between layers.
While the resulting layout might not be ideal, it is much better than the one without decrossing at all.

\subsection{Technical Details}

Since the amount of data a user may query is large, the application is split into a frontend and a backend.
The backend is responsible for storing the data and fetching required information from the underlying database.
The frontend serves as an interactive interface to the data and provides the visualization.
This avoids excessive memory consumption and speeds up computations, as the client queries data from the server on a need-to-know basis.

On the frontend, state management, interactivity, and DOM manipulation is all done with the Vue framework.
This differs from many web-based visualizations that use D3 for DOM manipulation.
We chose this setup because \ourmethod contains many distinct components whose state must be kept synchronized.
This includes not only the visualizations, but also user interface elements like the search bar.
Vue's model of reactivity can easily maintain consistent state across the entire application.
While \ourmethod does not use D3 to directly manipulate the DOM, it still does use it for other visualization-related computations.
Decrossing is calculated using web workers to allow early termination if the thread takes too long.

Our backend is a Node.js application that serves JSON with a standard REST-style architecture.
Data is stored in a SQLite database that has been indexed to achieve lookups as fast as possible.
A stable network connection is required for real-time interaction.

\begin{figure}[tb]
 \centering
 \includegraphics[width=\columnwidth]{img/no_decross.png}
 \includegraphics[width=\columnwidth]{img/decross.png}
 \caption{Comparison of type flows without decrossing (above) and with decrossing (below).}
 \label{fig:decross}
\end{figure}

%%

\section{Evaluation}

In accordance with the design study ``lite'' methodology~\cite{syeda:2020}, we conducted a small-scale qualitative usability study and received feedback from $18$ individuals. Many respondents had some trouble interpreting the visualization or at least commented that the learning curve was steep. Given that the domain is niche and the flow-based idiom for visualizing signatures is novel, this was not unexpected.

To alleviate some of this confusion, we incorporated elements that give explicit explanations for different components. These appear as question mark icons that, upon hovering, give a complete description of the corresponding component. For more details, we also provide a full page of step-by-step instructions.

%% TODO: Alexi will possibly add evaluation notes here.

%%

\section{Limitations and Future Work}

Designed with a specific use case in mind, \ourmethod suffers from some shortcomings and does not fully address the entire range of tasks a language designer may need to perform.

In particular, \ourmethod does not allow for exploring type information at differing granularities.
R supports a range of data types including ones containing dimensionality information.
For example, an R array may have type {\tt integer[3]} indicating that it is an array of length $3$.
Every such type will get compressed down to a simpler array type {\tt integer[]}.
Reducing the number of types can make the visualization more understandable, at the expensive of losing precision in type information.
Ideally, a user would be able to interactively tune the level of granularity based on their interest.
Such a feature would be especially helpful for R, because values can come attached with lots of relevant data such as the dynamic dispatch method or user-specified metadata.

Filtering is a central mechanism of our system, but it also comes at a cost.
If one has a specific function or several functions in mind, then \ourmethod provides a useful local view of that information.
It does not support, however, any kind of global view of type information across a large number of functions.
When the amount of flows or nodes becomes too great, the visualization will start paginating, making comparisons across all flows impossible.
Aggregation and summarization would be key to making a global view of the data feasible, but that remains future work.

%%

\section{Conclusion}

We have presented \ourmethod, an interactive visualization of run-time type information that supports real-time analysis and exploration.
The tool was instantiated with a massive data set of execution traces from a corpus of popular R packages.

\ourmethod provides facilities for filtering, searching, understanding, and comparing type information.
Type signatures of function calls are represented as flows traversing each argument type and return type in sequence.
Quick function lookup is supported by a search bar, with package and function treemaps facilitating function exploration.
Various interactions provide additional details and assist users with comprehension and navigation.

Our system is aimed at elucidating how R programmers use the language in the field.
Specifically, the data and visualization will be used to inform the design of a future gradual type system for R.
However, \ourmethod is not tied to the R ecosystem and is suitable to use for any language that supports run-time type information.
The visualization could yield insights useful for purposes other than gradual typing, and beyond what we have considered.

We hope that, in the future, programming language designers will collect and use empirical data about their languages more extensively.
Such data could be used to make informed decisions about design, where the cost of making a mistake is high.
Visualization will be unavoidable in these scenarios since semantically-meaning information about programs is rich in structure.
Generic, canned visualizations will not be sufficient. \ourmethod is a first step in this direction.

\acknowledgments{
  The authors wish to thank Younes El Idrissi Yazami, Petr Maj, the students of CS 7250, and contributors to all the open source projects that \ourmethod uses.
  This work was supported in part by a Northeastern Graduate Fellowship.
}

\bibliographystyle{abbrv-doi-hyperref}

\bibliography{main}
\end{document}
